{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28d680f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making sure we train with our GPU, Pytorch is the fucking shit!!!\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be60c88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "338cd529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44eeffff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x1ec095b0890>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db9e047c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA TITAN RTX'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19d12063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (2445944, 17)\n",
      "NaN values in each column:\n",
      " OPEN                                1\n",
      "HIGH                                1\n",
      "LOW                                 1\n",
      "CLOSE                               1\n",
      "TICKVOL                             1\n",
      "VOL                                 1\n",
      "SPREAD                              1\n",
      "Change_Open_Close                   1\n",
      "Change_High_Low                     1\n",
      "Up_Or_Down                    1078761\n",
      "Profit_Between_Time_Series          1\n",
      "Buy_Signal                     930747\n",
      "Sell_Signal                    930747\n",
      "Unnamed: 14                   2445944\n",
      "Unnamed: 15                   2445943\n",
      "Short_Signal                  1515198\n",
      "CloseShort_Signal             1515198\n",
      "dtype: int64\n",
      "Combined data shape after handling NaNs: (2445943, 15)\n",
      "Features shape: (2445943, 11), Buy labels shape: (2445943,), Sell labels shape: (2445943,), Short labels shape: (2445943,), CloseShort labels shape: (2445943,)\n",
      "Data Loaders created successfully!\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set multiprocessing method\n",
    "torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Custom Dataset class with exception handling\n",
    "class BitcoinDataset(Dataset):\n",
    "    def __init__(self, features, buy_labels, sell_labels, short_labels, closeshort_labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.buy_labels = torch.tensor(buy_labels, dtype=torch.long)\n",
    "        self.sell_labels = torch.tensor(sell_labels, dtype=torch.long)\n",
    "        self.short_labels = torch.tensor(short_labels, dtype=torch.long)\n",
    "        self.closeshort_labels = torch.tensor(closeshort_labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buy_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            features = self.features[idx]\n",
    "            buy_label = self.buy_labels[idx]\n",
    "            sell_label = self.sell_labels[idx]\n",
    "            short_label = self.short_labels[idx]\n",
    "            closeshort_label = self.closeshort_labels[idx]\n",
    "            return features, buy_label, sell_label, short_label, closeshort_label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data at index {idx}: {e}\")\n",
    "            return torch.tensor([]), torch.tensor([]), torch.tensor([]), torch.tensor([]), torch.tensor([])  # Return empty tensors on error\n",
    "\n",
    "# Load the preprocessed data\n",
    "data_paths = {\n",
    "    'minute1': 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/minute1_trained.csv',\n",
    "    'minute1_2': 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/bitcoinm1_2_cleaned.csv',\n",
    "    'minute5': 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/minute5_trained.csv',\n",
    "    'minute15': 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/minute15_trained.csv',\n",
    "    'minute30': 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/minute30_trained.csv',\n",
    "    'minute1_short': 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/allshortingdata/minute1short_trained.csv',\n",
    "    'minute1_2short': 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/allshortingdata/bitcoinm1_2_cleanedshort.csv',\n",
    "    'minute5short': 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/allshortingdata/minute5short_trained.csv',\n",
    "    'minute15short': 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/allshortingdata/minute15short_trained.csv',\n",
    "    'minute30short': 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/allshortingdata/minute30short_trained.csv'\n",
    "}\n",
    "\n",
    "# Function to load and concatenate datasets\n",
    "def load_data(data_paths):\n",
    "    data_frames = []\n",
    "    for key, path in data_paths.items():\n",
    "        df = pd.read_csv(path, dtype={'DateTime': str})  # Specify dtype for 'DateTime' column\n",
    "        df['DateTime'] = pd.to_datetime(df['DateTime'], errors='coerce')  # Convert 'DateTime' to datetime\n",
    "        df = df.set_index('DateTime')\n",
    "        data_frames.append(df)\n",
    "    combined_data = pd.concat(data_frames, axis=0)\n",
    "    return combined_data\n",
    "\n",
    "# Load and combine datasets\n",
    "combined_data = load_data(data_paths)\n",
    "\n",
    "# Debug: print the shape of the combined data\n",
    "print(f\"Combined data shape: {combined_data.shape}\")\n",
    "\n",
    "# Debug: check for NaNs in the data\n",
    "nan_info = combined_data.isna().sum()\n",
    "print(\"NaN values in each column:\\n\", nan_info)\n",
    "\n",
    "# Fill or drop NaNs in critical columns\n",
    "combined_data['Up_Or_Down'].fillna(0, inplace=True)\n",
    "combined_data['Buy_Signal'].fillna(0, inplace=True)\n",
    "combined_data['Sell_Signal'].fillna(0, inplace=True)\n",
    "combined_data['Short_Signal'].fillna(0, inplace=True)\n",
    "combined_data['CloseShort_Signal'].fillna(0, inplace=True)\n",
    "\n",
    "# Drop rows where essential columns are still NaN\n",
    "combined_data.dropna(subset=['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL', 'VOL', 'SPREAD'], inplace=True)\n",
    "\n",
    "# Drop columns that are completely NaN\n",
    "combined_data.drop(columns=['Unnamed: 14', 'Unnamed: 15'], inplace=True)\n",
    "\n",
    "# Replace infinite values with NaN and then drop them\n",
    "combined_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "combined_data.dropna(inplace=True)\n",
    "\n",
    "# Debug: print the shape of the combined data after handling NaNs\n",
    "print(f\"Combined data shape after handling NaNs: {combined_data.shape}\")\n",
    "\n",
    "# Separate features and labels\n",
    "features = combined_data.drop(columns=['Buy_Signal', 'Sell_Signal', 'Short_Signal', 'CloseShort_Signal']).values\n",
    "buy_labels = combined_data['Buy_Signal'].values\n",
    "sell_labels = combined_data['Sell_Signal'].values\n",
    "short_labels = combined_data['Short_Signal'].values\n",
    "closeshort_labels = combined_data['CloseShort_Signal'].values\n",
    "\n",
    "# Debug: print the shapes of features and labels\n",
    "print(f\"Features shape: {features.shape}, Buy labels shape: {buy_labels.shape}, Sell labels shape: {sell_labels.shape}, Short labels shape: {short_labels.shape}, CloseShort labels shape: {closeshort_labels.shape}\")\n",
    "\n",
    "# Split the data\n",
    "train_features, test_features, train_buy_labels, test_buy_labels, train_sell_labels, test_sell_labels, train_short_labels, test_short_labels, train_closeshort_labels, test_closeshort_labels = train_test_split(\n",
    "    features, buy_labels, sell_labels, short_labels, closeshort_labels, test_size=0.2, shuffle=False)\n",
    "\n",
    "train_features, val_features, train_buy_labels, val_buy_labels, train_sell_labels, val_sell_labels, train_short_labels, val_short_labels, train_closeshort_labels, val_closeshort_labels = train_test_split(\n",
    "    train_features, train_buy_labels, train_sell_labels, train_short_labels, train_closeshort_labels, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "# Check data for NaNs and infinities\n",
    "def check_data_for_nans(features, labels):\n",
    "    if np.isnan(features).any() or np.isnan(labels).any():\n",
    "        raise ValueError(\"Data contains NaNs\")\n",
    "    if np.isinf(features).any() or np.isinf(labels).any():\n",
    "        raise ValueError(\"Data contains infinite values\")\n",
    "\n",
    "# Check training and validation data\n",
    "check_data_for_nans(train_features, train_buy_labels)\n",
    "check_data_for_nans(val_features, val_buy_labels)\n",
    "check_data_for_nans(train_features, train_sell_labels)\n",
    "check_data_for_nans(val_features, val_sell_labels)\n",
    "check_data_for_nans(train_features, train_short_labels)\n",
    "check_data_for_nans(val_features, val_short_labels)\n",
    "check_data_for_nans(train_features, train_closeshort_labels)\n",
    "check_data_for_nans(val_features, val_closeshort_labels)\n",
    "\n",
    "# Create DataLoader function with conditional persistent_workers\n",
    "def create_dataloader(features, buy_labels, sell_labels, short_labels, closeshort_labels, batch_size=12288, shuffle=True, num_workers=0):\n",
    "    dataset = BitcoinDataset(features, buy_labels, sell_labels, short_labels, closeshort_labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True,\n",
    "                            persistent_workers=num_workers > 0)\n",
    "    return dataloader\n",
    "\n",
    "# Define batch_size\n",
    "batch_size = 12288  # Adjust to fit GPU memory\n",
    "\n",
    "# Create DataLoaders for signals\n",
    "train_loader = create_dataloader(train_features, train_buy_labels, train_sell_labels, train_short_labels, train_closeshort_labels, batch_size, num_workers=0)\n",
    "val_loader = create_dataloader(val_features, val_buy_labels, val_sell_labels, val_short_labels, val_closeshort_labels, batch_size, num_workers=0)\n",
    "test_loader = create_dataloader(test_features, test_buy_labels, test_sell_labels, test_short_labels, test_closeshort_labels, batch_size, num_workers=0)\n",
    "\n",
    "print(\"Data Loaders created successfully!\")\n",
    "\n",
    "# Set the device for training (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a57424cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, loss function, and optimizer created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the RNN model\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the RNN model\n",
    "class BitcoinPriceLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(BitcoinPriceLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5_buy = nn.Linear(hidden_size, output_size)\n",
    "        self.fc5_sell = nn.Linear(hidden_size, output_size)\n",
    "        self.fc5_short = nn.Linear(hidden_size, output_size)\n",
    "        self.fc5_closeshort = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = torch.relu(self.fc2(out))  # Added another activation\n",
    "        out = torch.relu(self.fc3(out))  # Added another activation\n",
    "        out = torch.relu(self.fc4(out))  # Added another activation\n",
    "        buy_out = self.fc5_buy(out)\n",
    "        sell_out = self.fc5_sell(out)\n",
    "        short_out = self.fc5_short(out)\n",
    "        closeshort_out = self.fc5_closeshort(out)\n",
    "        return buy_out, sell_out, short_out, closeshort_out\n",
    "\n",
    "# Model parameters\n",
    "input_size = combined_data.shape[1] - 4  # Number of features (exclude 'Buy_Signal', 'Sell_Signal', 'Short_Signal', 'CloseShort_Signal')\n",
    "hidden_size = 1024  # Reduced hidden size\n",
    "num_layers = 6  # Reduced number of layers\n",
    "output_size = 2  # Binary classification (up or down)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = BitcoinPriceLSTM(input_size, hidden_size, num_layers, output_size, dropout=0.3).to(device)\n",
    "\n",
    "# Initialize weights\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name or 'weight_hh' in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param.data, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)  # Adjusted learning rate\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "print(\"Model, loss function, and optimizer created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cfadd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 50,438,152 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# Function to count the number of parameters in a model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print the number of parameters in the model\n",
    "num_params = count_parameters(model)\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "499cd412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure we are training fully on our GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7093690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|████████████████████████████████████████████████████████████████| 128/128 [00:40<00:00,  3.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.4078, Val Loss: 1.2713, Time: 49.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|████████████████████████████████████████████████████████████████| 128/128 [00:40<00:00,  3.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Loss: 0.1883, Val Loss: 1.2774, Time: 49.57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|████████████████████████████████████████████████████████████████| 128/128 [00:40<00:00,  3.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Loss: 0.1829, Val Loss: 1.1920, Time: 49.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|████████████████████████████████████████████████████████████████| 128/128 [00:40<00:00,  3.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Loss: 0.1791, Val Loss: 1.2893, Time: 49.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|████████████████████████████████████████████████████████████████| 128/128 [00:40<00:00,  3.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Loss: 0.1764, Val Loss: 1.1936, Time: 49.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|████████████████████████████████████████████████████████████████| 128/128 [00:40<00:00,  3.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Loss: 0.1739, Val Loss: 1.4613, Time: 49.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|████████████████████████████████████████████████████████████████| 128/128 [00:40<00:00,  3.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Loss: 0.1732, Val Loss: 1.6291, Time: 49.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100:  38%|████████████████████████▉                                        | 49/128 [00:15<00:25,  3.09batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 104\u001b[0m\n\u001b[0;32m    100\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    102\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m--> 104\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)\n\u001b[0;32m    106\u001b[0m plot_losses(train_losses, val_losses)\n",
      "Cell \u001b[1;32mIn[21], line 29\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience)\u001b[0m\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[1;32m---> 29\u001b[0m     buy_out, sell_out, short_out, closeshort_out \u001b[38;5;241m=\u001b[39m model(features\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Add batch dimension for LSTM\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     buy_loss \u001b[38;5;241m=\u001b[39m criterion(buy_out, buy_labels)\n\u001b[0;32m     31\u001b[0m     sell_loss \u001b[38;5;241m=\u001b[39m criterion(sell_out, sell_labels)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 24\u001b[0m, in \u001b[0;36mBitcoinPriceLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     23\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 24\u001b[0m     c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     25\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x, (h0, c0))\n\u001b[0;32m     26\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training function\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=100, patience=10):\n",
    "    scaler = GradScaler()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for features, buy_labels, sell_labels, short_labels, closeshort_labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n",
    "            features = features.to(device, non_blocking=True)\n",
    "            buy_labels = buy_labels.to(device, non_blocking=True)\n",
    "            sell_labels = sell_labels.to(device, non_blocking=True)\n",
    "            short_labels = short_labels.to(device, non_blocking=True)\n",
    "            closeshort_labels = closeshort_labels.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                buy_out, sell_out, short_out, closeshort_out = model(features.unsqueeze(1))  # Add batch dimension for LSTM\n",
    "                buy_loss = criterion(buy_out, buy_labels)\n",
    "                sell_loss = criterion(sell_out, sell_labels)\n",
    "                short_loss = criterion(short_out, short_labels)\n",
    "                closeshort_loss = criterion(closeshort_out, closeshort_labels)\n",
    "                loss = buy_loss + sell_loss + short_loss + closeshort_loss\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item() * features.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        val_loss = validate_model(model, val_loader, criterion)\n",
    "        \n",
    "        train_losses.append(epoch_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Time: {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                model.load_state_dict(torch.load('best_model.pth'))\n",
    "                break\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, buy_labels, sell_labels, short_labels, closeshort_labels in val_loader:\n",
    "            features = features.to(device, non_blocking=True)\n",
    "            buy_labels = buy_labels.to(device, non_blocking=True)\n",
    "            sell_labels = sell_labels.to(device, non_blocking=True)\n",
    "            short_labels = short_labels.to(device, non_blocking=True)\n",
    "            closeshort_labels = closeshort_labels.to(device, non_blocking=True)\n",
    "            \n",
    "            with autocast():\n",
    "                buy_out, sell_out, short_out, closeshort_out = model(features.unsqueeze(1))  # Add batch dimension for LSTM\n",
    "                buy_loss = criterion(buy_out, buy_labels)\n",
    "                sell_loss = criterion(sell_out, sell_labels)\n",
    "                short_loss = criterion(short_out, short_labels)\n",
    "                closeshort_loss = criterion(closeshort_out, closeshort_labels)\n",
    "                loss = buy_loss + sell_loss + short_loss + closeshort_loss\n",
    "            \n",
    "            running_loss += loss.item() * features.size(0)\n",
    "    \n",
    "    val_loss = running_loss / len(val_loader.dataset)\n",
    "    return val_loss\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.show()\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "train_losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)\n",
    "\n",
    "plot_losses(train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb3159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1 Score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs.unsqueeze(1))  # Add batch dimension for LSTM\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    test_loss = running_loss / len(test_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    \n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Evaluate on test_buy_loader or test_sell_loader depending on your focus\n",
    "all_labels, all_preds = evaluate_model(model, test_buy_loader, criterion)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model:\n",
    "import torch\n",
    "\n",
    "# Save the entire model\n",
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backtesting--Getting our Trained model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the LSTM model\n",
    "class BitcoinPriceLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(BitcoinPriceLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = torch.relu(self.fc2(out))  # Added another activation\n",
    "        out = torch.relu(self.fc3(out))  # Added another activation\n",
    "        out = torch.relu(self.fc4(out))  # Added another activation\n",
    "        out = self.fc5(out)\n",
    "        return out\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model parameters\n",
    "input_size = 11  # Adjust based on the number of features excluding 'Buy_Signal' and 'Sell_Signal'\n",
    "hidden_size = 1024\n",
    "num_layers = 6\n",
    "output_size = 2\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"C:/Users/gunne/Documents/PriceNeuralNetwork/model.pth\"\n",
    "model = BitcoinPriceLSTM(input_size, hidden_size, num_layers, output_size, dropout=0.5).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Load the backtest data\n",
    "backtest_data_path = 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/1walk_cleaned.csv'\n",
    "backtest_data = pd.read_csv(backtest_data_path, parse_dates=['DateTime'], index_col='DateTime')\n",
    "\n",
    "# Feature engineering\n",
    "backtest_data['Change_Open_Close'] = ((backtest_data['CLOSE'] - backtest_data['OPEN']) / backtest_data['OPEN']) * 100\n",
    "backtest_data['Change_High_Low'] = ((backtest_data['HIGH'] - backtest_data['LOW']) / backtest_data['HIGH']) * 100\n",
    "backtest_data['Up_Or_Down'] = (backtest_data['Change_Open_Close'].diff() > 0).astype(int)\n",
    "backtest_data['Profit_Between_Time_Series'] = backtest_data['Change_Open_Close'].diff().fillna(0)\n",
    "backtest_data['Buy_Signal'] = (backtest_data['Profit_Between_Time_Series'] > 0.165).astype(int)\n",
    "backtest_data['Sell_Signal'] = backtest_data['Buy_Signal'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "# Prepare features for model prediction\n",
    "features = backtest_data.drop(columns=['Buy_Signal', 'Sell_Signal']).values\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Predicting buy signals\n",
    "with torch.no_grad():\n",
    "    inputs = torch.tensor(scaled_features, dtype=torch.float32).to(device)\n",
    "    outputs = model(inputs.unsqueeze(1))\n",
    "    predicted_signals = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "backtest_data['Predicted_Buy_Signal'] = predicted_signals\n",
    "\n",
    "# Backtesting with leverage and profit cap\n",
    "initial_capital = 100\n",
    "capital = initial_capital\n",
    "leverage = 100  # 1:100 leverage\n",
    "capital_history = []\n",
    "\n",
    "# Profit cap parameter\n",
    "profit_cap_percentage = 0.165  # Cap the profit at this percentage\n",
    "target_capital = 200000  # Target capital to stop trading\n",
    "\n",
    "# Trade log\n",
    "trade_log = []\n",
    "\n",
    "# Initialize variables\n",
    "entry_price = None\n",
    "positions = 0\n",
    "\n",
    "for i in range(len(backtest_data)):\n",
    "    date_time = backtest_data.index[i]\n",
    "    current_price = backtest_data['CLOSE'].iloc[i]\n",
    "\n",
    "    if capital >= target_capital:\n",
    "        print(f\"Target capital of {target_capital} reached at {date_time}, stopping trading.\")\n",
    "        break\n",
    "\n",
    "    if backtest_data['Predicted_Buy_Signal'].iloc[i] == 1 and positions == 0:\n",
    "        # Enter position\n",
    "        positions = leverage * (capital / current_price)\n",
    "        entry_price = current_price\n",
    "        trade_log.append(f\"Entered position at {date_time}, index {i}, price: {entry_price}, positions: {positions}, capital: {capital}\")\n",
    "    \n",
    "    if positions != 0:\n",
    "        profit_percentage = (current_price - entry_price) / entry_price * 100\n",
    "        \n",
    "        if profit_percentage >= profit_cap_percentage or profit_percentage <= -1:\n",
    "            \n",
    "            # Compound the capital if profit was made\n",
    "            if profit_percentage >= profit_cap_percentage:\n",
    "                capital *= (1 + (profit_percentage / 100) * leverage)\n",
    "                \n",
    "            trade_log.append(f\"Exited position at {date_time}, index {i}, price: {current_price}, profit_percentage: {profit_percentage}, capital: {capital}\")\n",
    "            \n",
    "            # Reset positions\n",
    "            positions = 0\n",
    "            entry_price = None\n",
    "    \n",
    "    # Update capital history\n",
    "    capital_history.append(capital)\n",
    "\n",
    "# Fill the remaining capital history with the final capital value\n",
    "if len(capital_history) < len(backtest_data):\n",
    "    capital_history.extend([capital] * (len(backtest_data) - len(capital_history)))\n",
    "\n",
    "# Output trade log\n",
    "for log in trade_log:\n",
    "    print(log)\n",
    "\n",
    "# Plotting the results\n",
    "backtest_data['Capital'] = capital_history\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(backtest_data.index, backtest_data['CLOSE'], label='Market Price')\n",
    "plt.scatter(backtest_data.index[backtest_data['Predicted_Buy_Signal'] == 1], backtest_data['CLOSE'][backtest_data['Predicted_Buy_Signal'] == 1], marker='^', color='green', alpha=1, label='Buy Signal')\n",
    "plt.scatter(backtest_data.index[backtest_data['Predicted_Buy_Signal'] == 0], backtest_data['CLOSE'][backtest_data['Predicted_Buy_Signal'] == 0], marker='v', color='red', alpha=1, label='Sell Signal')\n",
    "plt.title('Backtest Trading Performance')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(backtest_data.index, backtest_data['Capital'], label='Capital')\n",
    "plt.axhline(y=initial_capital, color='r', linestyle='--', label='Initial Capital')\n",
    "plt.axhline(y=target_capital, color='g', linestyle='--', label='Target Capital')\n",
    "plt.title('Capital Growth Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Capital')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate performance metrics\n",
    "actual_signals = backtest_data['Buy_Signal'].values\n",
    "precision = precision_score(actual_signals, predicted_signals)\n",
    "recall = recall_score(actual_signals, predicted_signals)\n",
    "f1 = f1_score(actual_signals, predicted_signals)\n",
    "accuracy = accuracy_score(actual_signals, predicted_signals)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backtesting-with forex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the LSTM model\n",
    "class BitcoinPriceLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(BitcoinPriceLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = torch.relu(self.fc2(out))  # Added another activation\n",
    "        out = torch.relu(self.fc3(out))  # Added another activation\n",
    "        out = torch.relu(self.fc4(out))  # Added another activation\n",
    "        out = self.fc5(out)\n",
    "        return out\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model parameters\n",
    "input_size = 11  # Adjust based on the number of features excluding 'Buy_Signal' and 'Sell_Signal'\n",
    "hidden_size = 1024\n",
    "num_layers = 6\n",
    "output_size = 2\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"C:/Users/gunne/Documents/PriceNeuralNetwork/model.pth\"\n",
    "model = BitcoinPriceLSTM(input_size, hidden_size, num_layers, output_size, dropout=0.5).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Load the backtest data\n",
    "backtest_data_path = 'C:/Users/gunne/OneDrive/Desktop/bitcoin/trained/1monthforex_cleaned.csv'\n",
    "backtest_data = pd.read_csv(backtest_data_path, parse_dates=['DateTime'], index_col='DateTime')\n",
    "\n",
    "# Feature engineering\n",
    "backtest_data['Change_Open_Close'] = ((backtest_data['CLOSE'] - backtest_data['OPEN']) / backtest_data['OPEN']) * 100\n",
    "backtest_data['Change_High_Low'] = ((backtest_data['HIGH'] - backtest_data['LOW']) / backtest_data['HIGH']) * 100\n",
    "backtest_data['Up_Or_Down'] = (backtest_data['Change_Open_Close'].diff() > 0).astype(int)\n",
    "backtest_data['Profit_Between_Time_Series'] = backtest_data['Change_Open_Close'].diff().fillna(0)\n",
    "backtest_data['Buy_Signal'] = (backtest_data['Profit_Between_Time_Series'] > 0.165).astype(int)\n",
    "backtest_data['Sell_Signal'] = backtest_data['Buy_Signal'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "# Prepare features for model prediction\n",
    "features = backtest_data.drop(columns=['Buy_Signal', 'Sell_Signal']).values\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Predicting buy signals\n",
    "with torch.no_grad():\n",
    "    inputs = torch.tensor(scaled_features, dtype=torch.float32).to(device)\n",
    "    outputs = model(inputs.unsqueeze(1))\n",
    "    predicted_signals = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "backtest_data['Predicted_Buy_Signal'] = predicted_signals\n",
    "\n",
    "# Backtesting with leverage and profit cap\n",
    "initial_capital = 1000\n",
    "capital = initial_capital\n",
    "leverage = 100  # 1:100 leverage\n",
    "capital_history = []\n",
    "\n",
    "# Profit cap parameter\n",
    "profit_cap_percentage = 0.165  # Cap the profit at this percentage\n",
    "target_capital = 200000  # Target capital to stop trading\n",
    "\n",
    "# Trade log\n",
    "trade_log = []\n",
    "\n",
    "# Initialize variables\n",
    "entry_price = None\n",
    "positions = 0\n",
    "\n",
    "for i in range(len(backtest_data)):\n",
    "    date_time = backtest_data.index[i]\n",
    "    current_price = backtest_data['CLOSE'].iloc[i]\n",
    "\n",
    "    if capital >= target_capital:\n",
    "        print(f\"Target capital of {target_capital} reached at {date_time}, stopping trading.\")\n",
    "        break\n",
    "\n",
    "    if backtest_data['Predicted_Buy_Signal'].iloc[i] == 1 and positions == 0:\n",
    "        # Enter position\n",
    "        positions = leverage * (capital / current_price)\n",
    "        entry_price = current_price\n",
    "        trade_log.append(f\"Entered position at {date_time}, index {i}, price: {entry_price}, positions: {positions}, capital: {capital}\")\n",
    "    \n",
    "    if positions != 0:\n",
    "        profit_percentage = (current_price - entry_price) / entry_price * 100\n",
    "        \n",
    "        if profit_percentage >= profit_cap_percentage or profit_percentage <= -1:\n",
    "            \n",
    "            # Compound the capital if profit was made\n",
    "            if profit_percentage >= profit_cap_percentage:\n",
    "                capital *= (1 + (profit_percentage / 100) * leverage)\n",
    "                \n",
    "            trade_log.append(f\"Exited position at {date_time}, index {i}, price: {current_price}, profit_percentage: {profit_percentage}, capital: {capital}\")\n",
    "            \n",
    "            # Reset positions\n",
    "            positions = 0\n",
    "            entry_price = None\n",
    "    \n",
    "    # Update capital history\n",
    "    capital_history.append(capital)\n",
    "\n",
    "# Fill the remaining capital history with the final capital value\n",
    "if len(capital_history) < len(backtest_data):\n",
    "    capital_history.extend([capital] * (len(backtest_data) - len(capital_history)))\n",
    "\n",
    "# Output trade log\n",
    "for log in trade_log:\n",
    "    print(log)\n",
    "\n",
    "# Plotting the results\n",
    "backtest_data['Capital'] = capital_history\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(backtest_data.index, backtest_data['CLOSE'], label='Market Price')\n",
    "plt.scatter(backtest_data.index[backtest_data['Predicted_Buy_Signal'] == 1], backtest_data['CLOSE'][backtest_data['Predicted_Buy_Signal'] == 1], marker='^', color='green', alpha=1, label='Buy Signal')\n",
    "plt.scatter(backtest_data.index[backtest_data['Predicted_Buy_Signal'] == 0], backtest_data['CLOSE'][backtest_data['Predicted_Buy_Signal'] == 0], marker='v', color='red', alpha=1, label='Sell Signal')\n",
    "plt.title('Backtest Trading Performance')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(backtest_data.index, backtest_data['Capital'], label='Capital')\n",
    "plt.axhline(y=initial_capital, color='r', linestyle='--', label='Initial Capital')\n",
    "plt.axhline(y=target_capital, color='g', linestyle='--', label='Target Capital')\n",
    "plt.title('Capital Growth Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Capital')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate performance metrics\n",
    "actual_signals = backtest_data['Buy_Signal'].values\n",
    "precision = precision_score(actual_signals, predicted_signals)\n",
    "recall = recall_score(actual_signals, predicted_signals)\n",
    "f1 = f1_score(actual_signals, predicted_signals)\n",
    "accuracy = accuracy_score(actual_signals, predicted_signals)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353185a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backtesting--Connecting with MetaTrader5 data with ICMarketsSC-Demo Bitcoin account \n",
    "# Install Required Packages\n",
    "!pip install --upgrade pip\n",
    "!pip install --force-reinstall --no-binary :all: tbb\n",
    "!pip install MetaTrader5 pandas numpy torch matplotlib scikit-learn\n",
    "\n",
    "# Imports and Model Definition\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the LSTM model\n",
    "class BitcoinPriceLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(BitcoinPriceLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = torch.relu(self.fc2(out))\n",
    "        out = torch.relu(self.fc3(out))\n",
    "        out = torch.relu(self.fc4(out))\n",
    "        out = self.fc5(out)\n",
    "        return out\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"C:/Users/gunne/Documents/PriceNeuralNetwork/model.pth\"\n",
    "model = BitcoinPriceLSTM(input_size=11, hidden_size=1024, num_layers=6, output_size=2, dropout=0.5).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Connect to MetaTrader 5\n",
    "if not mt5.initialize():\n",
    "    print(\"initialize() failed\")\n",
    "    mt5.shutdown()\n",
    "else:\n",
    "    print(\"MetaTrader 5 initialized successfully\")\n",
    "\n",
    "# Login to the demo account\n",
    "account = 51806647  # Ensure the account number is an integer\n",
    "password = \"lKDtOjEK6$rp@f\"\n",
    "server = \"ICMarketsSC-Demo\"\n",
    "\n",
    "# Debug print for login details\n",
    "print(f\"Attempting to login with Account: {account}, Password: {password}, Server: {server}\")\n",
    "\n",
    "authorized = mt5.login(login=account, password=password, server=server)\n",
    "if not authorized:\n",
    "    print(f\"Failed to connect to account #{account}, error code: {mt5.last_error()}\")\n",
    "else:\n",
    "    print(f\"Connected to account #{account}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backtesting--Part 2\n",
    "# Fetch historical data from MetaTrader 5\n",
    "symbol = \"BTCUSD\"\n",
    "timeframe = mt5.TIMEFRAME_M1\n",
    "utc_from = datetime.datetime(2022, 6, 1)\n",
    "utc_to = datetime.datetime(2022, 7, 1)\n",
    "rates = mt5.copy_rates_range(symbol, timeframe, utc_from, utc_to)\n",
    "if rates is None:\n",
    "    print(\"Failed to fetch rates, error code:\", mt5.last_error())\n",
    "else:\n",
    "    print(f\"Fetched {len(rates)} rates\")\n",
    "\n",
    "# Create DataFrame from the rates\n",
    "rates_frame = pd.DataFrame(rates)\n",
    "rates_frame['time'] = pd.to_datetime(rates_frame['time'], unit='s')\n",
    "rates_frame.set_index('time', inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "rates_frame['Change_Open_Close'] = ((rates_frame['close'] - rates_frame['open']) / rates_frame['open']) * 100\n",
    "rates_frame['Change_High_Low'] = ((rates_frame['high'] - rates_frame['low']) / rates_frame['high']) * 100\n",
    "rates_frame['Up_Or_Down'] = (rates_frame['Change_Open_Close'].diff() > 0).astype(int)\n",
    "rates_frame['Profit_Between_Time_Series'] = rates_frame['Change_Open_Close'].diff().fillna(0)\n",
    "rates_frame['Buy_Signal'] = (rates_frame['Profit_Between_Time_Series'] > 0.165).astype(int)\n",
    "rates_frame['Sell_Signal'] = rates_frame['Buy_Signal'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "# Prepare features for model prediction\n",
    "features = rates_frame.drop(columns=['Buy_Signal', 'Sell_Signal']).values\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Predicting buy signals\n",
    "with torch.no_grad():\n",
    "    inputs = torch.tensor(scaled_features, dtype=torch.float32).to(device)\n",
    "    outputs = model(inputs.unsqueeze(1))\n",
    "    predicted_signals = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "rates_frame['Predicted_Buy_Signal'] = predicted_signals\n",
    "\n",
    "# Backtesting with leverage and profit cap\n",
    "initial_capital = 100\n",
    "risk_per_trade = 10  # Risking $10 per trade\n",
    "capital = initial_capital\n",
    "leverage = 100  # 1:100 leverage\n",
    "capital_history = []\n",
    "\n",
    "# Profit cap parameter\n",
    "profit_cap_percentage = 0.165  # Cap the profit at this percentage\n",
    "\n",
    "# Trade log\n",
    "trade_log = []\n",
    "\n",
    "# Initialize variables\n",
    "entry_price = None\n",
    "positions = 0\n",
    "\n",
    "for i in range(len(rates_frame)):\n",
    "    date_time = rates_frame.index[i]\n",
    "    current_price = rates_frame['close'].iloc[i]\n",
    "\n",
    "    if rates_frame['Predicted_Buy_Signal'].iloc[i] == 1 and positions == 0:\n",
    "        # Enter position\n",
    "        positions = leverage * (risk_per_trade / current_price)\n",
    "        entry_price = current_price\n",
    "        trade_log.append(f\"Entered position at index {i}, time {date_time}, price: {entry_price}, positions: {positions}, capital: {capital}\")\n",
    "\n",
    "    if positions != 0:\n",
    "        profit_percentage = (current_price - entry_price) / entry_price * 100\n",
    "\n",
    "        if profit_percentage >= profit_cap_percentage or profit_percentage <= -1:\n",
    "            # Exit position due to reaching profit cap or stop loss\n",
    "            profit = positions * (current_price - entry_price) * leverage\n",
    "            capital += profit\n",
    "\n",
    "            trade_log.append(f\"Exited position at index {i}, time {date_time}, price: {current_price}, profit_percentage: {profit_percentage}, profit: {profit}, capital: {capital}\")\n",
    "\n",
    "            # Compound the capital if profit was made\n",
    "            if profit_percentage >= profit_cap_percentage:\n",
    "                capital += profit  # Add profit directly to capital\n",
    "\n",
    "            # Reset positions\n",
    "            positions = 0\n",
    "            entry_price = None\n",
    "\n",
    "    # Update capital history\n",
    "    capital_history.append(capital)\n",
    "\n",
    "# Output trade log\n",
    "for log in trade_log:\n",
    "    print(log)\n",
    "\n",
    "# Plotting the results\n",
    "rates_frame['Capital'] = capital_history\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(rates_frame.index, rates_frame['close'], label='Market Price')\n",
    "plt.scatter(rates_frame.index[rates_frame['Predicted_Buy_Signal'] == 1], rates_frame['close'][rates_frame['Predicted_Buy_Signal'] == 1], marker='^', color='green', alpha=1, label='Buy Signal')\n",
    "plt.scatter(rates_frame.index[rates_frame['Predicted_Buy_Signal'] == 0], rates_frame['close'][rates_frame['Predicted_Buy_Signal'] == 0], marker='v', color='red', alpha=1, label='Sell Signal')\n",
    "plt.title('Backtest Trading Performance')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(rates_frame.index, rates_frame['Capital'], label='Capital')\n",
    "plt.axhline(y=initial_capital, color='r', linestyle='--', label='Initial Capital')\n",
    "plt.axhline(y=200000, color='g', linestyle='--', label='Target Capital')\n",
    "plt.title('Capital Growth Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Capital')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backtesting--Continuous testing, for each minute, 60 minutes:\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Define the LSTM model\n",
    "class BitcoinPriceLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(BitcoinPriceLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = torch.relu(self.fc2(out))\n",
    "        out = torch.relu(self.fc3(out))\n",
    "        out = torch.relu(self.fc4(out))\n",
    "        out = self.fc5(out)\n",
    "        return out\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"C:/Users/gunne/Documents/PriceNeuralNetwork/model.pth\"\n",
    "model = BitcoinPriceLSTM(input_size=11, hidden_size=1024, num_layers=6, output_size=2, dropout=0.5).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Connect to MetaTrader 5\n",
    "if not mt5.initialize():\n",
    "    print(\"initialize() failed\")\n",
    "    mt5.shutdown()\n",
    "else:\n",
    "    print(\"MetaTrader 5 initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffad929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaTrader 5 initialized successfully\n",
      "Attempting to login with Account: 51806647, Password: lKDtOjEK6$rp@f, Server: ICMarketsSC-Demo\n",
      "Connected to account #51806647\n"
     ]
    }
   ],
   "source": [
    "#Backtesting\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Define the LSTM model\n",
    "class BitcoinPriceLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(BitcoinPriceLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = torch.relu(self.fc2(out))\n",
    "        out = torch.relu(self.fc3(out))\n",
    "        out = torch.relu(self.fc4(out))\n",
    "        out = self.fc5(out)\n",
    "        return out\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"C:/Users/gunne/Documents/PriceNeuralNetwork/model.pth\"\n",
    "model = BitcoinPriceLSTM(input_size=11, hidden_size=1024, num_layers=6, output_size=2, dropout=0.5).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Connect to MetaTrader 5\n",
    "if not mt5.initialize():\n",
    "    print(\"initialize() failed\")\n",
    "    mt5.shutdown()\n",
    "else:\n",
    "    print(\"MetaTrader 5 initialized successfully\")\n",
    "\n",
    "# Login to the demo account\n",
    "account = 51806647  # Ensure the account number is an integer\n",
    "password = \"lKDtOjEK6$rp@f\"\n",
    "server = \"ICMarketsSC-Demo\"\n",
    "\n",
    "# Debug print for login details\n",
    "print(f\"Attempting to login with Account: {account}, Password: {password}, Server: {server}\")\n",
    "\n",
    "authorized = mt5.login(login=account, password=password, server=server)\n",
    "if not authorized:\n",
    "    print(f\"Failed to connect to account #{account}, error code: {mt5.last_error()}\")\n",
    "else:\n",
    "    print(f\"Connected to account #{account}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7154f023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration at time 2024-05-26 06:53:16.281555, current price: 69056.86, positions: 0, capital: 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m         log_file\u001b[38;5;241m.\u001b[39mwrite(iteration_log \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# Wait before the next iteration (e.g., 1 minute)\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Optional: Save trade log to a file (this is redundant if we already save logs during each trade)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(log_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up initial capital and leverage\n",
    "# Set up initial capital and leverage\n",
    "initial_capital = 100\n",
    "risk_per_trade = 10  # Risk $10 per trade\n",
    "leverage = 100  # 1:100 leverage\n",
    "capital = initial_capital\n",
    "profit_cap_percentage = 0.165\n",
    "positions = 0\n",
    "entry_price = None\n",
    "\n",
    "# Trade log\n",
    "trade_log = []\n",
    "\n",
    "# Open trade log file in append mode\n",
    "log_file_path = \"trade_log.txt\"\n",
    "\n",
    "# Run the trading loop\n",
    "while True:\n",
    "    # Fetch live data\n",
    "    rates = mt5.copy_rates_from_pos(\"BTCUSD\", mt5.TIMEFRAME_M1, 0, 100)\n",
    "    rates_frame = pd.DataFrame(rates)\n",
    "    rates_frame['time'] = pd.to_datetime(rates_frame['time'], unit='s')\n",
    "    rates_frame.set_index('time', inplace=True)\n",
    "\n",
    "    # Feature engineering\n",
    "    rates_frame['Change_Open_Close'] = ((rates_frame['close'] - rates_frame['open']) / rates_frame['open']) * 100\n",
    "    rates_frame['Change_High_Low'] = ((rates_frame['high'] - rates_frame['low']) / rates_frame['high']) * 100\n",
    "    rates_frame['Up_Or_Down'] = (rates_frame['Change_Open_Close'].diff() > 0).astype(int)\n",
    "    rates_frame['Profit_Between_Time_Series'] = rates_frame['Change_Open_Close'].diff().fillna(0)\n",
    "    rates_frame['Buy_Signal'] = (rates_frame['Profit_Between_Time_Series'] > 0.165).astype(int)\n",
    "    rates_frame['Sell_Signal'] = rates_frame['Buy_Signal'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "    # Prepare features for model prediction\n",
    "    features = rates_frame.drop(columns=['Buy_Signal', 'Sell_Signal']).values\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Predicting buy signals\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(scaled_features, dtype=torch.float32).to(device)\n",
    "        outputs = model(inputs.unsqueeze(1))\n",
    "        predicted_signals = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "    rates_frame['Predicted_Buy_Signal'] = predicted_signals\n",
    "\n",
    "    # Execute trades based on predictions\n",
    "    current_price = rates_frame['close'].iloc[-1]\n",
    "\n",
    "    if rates_frame['Predicted_Buy_Signal'].iloc[-1] == 1 and positions == 0:\n",
    "        # Enter position\n",
    "        positions = leverage * (risk_per_trade / current_price)\n",
    "        entry_price = current_price\n",
    "        log_entry = f\"Entered position at time {datetime.datetime.now()}, price: {entry_price}, positions: {positions}, capital: {capital}\"\n",
    "        print(log_entry)\n",
    "        with open(log_file_path, \"a\") as log_file:\n",
    "            log_file.write(log_entry + \"\\n\")\n",
    "        trade_log.append(log_entry)\n",
    "\n",
    "    if positions != 0:\n",
    "        profit_percentage = (current_price - entry_price) / entry_price * 100\n",
    "\n",
    "        if profit_percentage >= profit_cap_percentage or profit_percentage <= -1:\n",
    "            # Exit position due to reaching profit cap or stop loss\n",
    "            profit = positions * (current_price - entry_price) * leverage\n",
    "            capital += profit\n",
    "            log_exit = f\"Exited position at time {datetime.datetime.now()}, price: {current_price}, profit_percentage: {profit_percentage}, profit: {profit}, capital: {capital}\"\n",
    "            print(log_exit)\n",
    "            with open(log_file_path, \"a\") as log_file:\n",
    "                log_file.write(log_exit + \"\\n\")\n",
    "            trade_log.append(log_exit)\n",
    "\n",
    "            # Compound the capital if profit was made\n",
    "            if profit_percentage >= profit_cap_percentage:\n",
    "                capital += profit  # Add profit directly to capital\n",
    "\n",
    "            # Reset positions\n",
    "            positions = 0\n",
    "            entry_price = None\n",
    "\n",
    "    # Print details of each iteration\n",
    "    iteration_log = f\"Iteration at time {datetime.datetime.now()}, current price: {current_price}, positions: {positions}, capital: {capital}\"\n",
    "    print(iteration_log)\n",
    "    with open(log_file_path, \"a\") as log_file:\n",
    "        log_file.write(iteration_log + \"\\n\")\n",
    "\n",
    "    # Wait before the next iteration (e.g., 1 minute)\n",
    "    time.sleep(60)\n",
    "\n",
    "# Optional: Save trade log to a file (this is redundant if we already save logs during each trade)\n",
    "with open(log_file_path, \"a\") as f:\n",
    "    for log in trade_log:\n",
    "        f.write(log + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108249de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
